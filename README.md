# ğŸ§Š The Coding Penguins â€” Automated Entity Extraction (Deviathon 2025)

A generative AI-powered system that automatically **extracts key entities** such as **Ministers, Judges, and Officials** from any given web domain.  
It combines **web crawling**, **NLP entity extraction**, and an interactive **Streamlit UI** for visualization.

Built by **Team The Coding Penguins** for **Deviathon 2025**.

---

## ğŸ‘¨â€ğŸ’» Team

| Name | Role | Responsibilities |
|------|------|------------------|
| ğŸ§ **Prakarsh Kaushik** | Team Lead & Backend/NLP | FastAPI backend, NLP extractor, integration |
| ğŸ§ **Om Upadhyay** | Crawler Developer | Web crawling & data collection |
| ğŸ§ **Pratiksha** | NLP & Rules | spaCy model tuning & entity linking |
| ğŸ§ **Priyanshu Gautam** | Frontend Developer | Streamlit UI & visualization |

---

## âš™ï¸ Tech Stack

- **Language:** Python 3.12  
- **Backend:** FastAPI  
- **Frontend:** Streamlit  
- **NLP:** spaCy (+ rule-based title matcher)  
- **Crawler:** Requests + BeautifulSoup  
- **Deployment:** Docker Compose (optional)

---

## ğŸš€ Features

- Crawl a domain and collect pages (JSONL)
- Extract PERSON â†” TITLE pairs (e.g., â€œRahul Sharma â€” Minister of Educationâ€)
- REST API for `/crawl`, `/extract`, `/results`
- Streamlit UI to run and visualize results
- Download structured JSON report

---

## ğŸ“ Project Structure

```text
The Coding Penguins/
â”‚
â”œâ”€â”€ api/                      # FastAPI backend
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ extractor/                # NLP extractor
â”‚   â”œâ”€â”€ nlp_pipeline.py
â”‚   â”œâ”€â”€ rules.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ crawler/                  # Web crawler (Om)
â”‚   â””â”€â”€ scraper.py
â”‚
â”œâ”€â”€ ui/                       # Streamlit frontend
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ data/                     # Input/output data
â”‚   â”œâ”€â”€ pages.jsonl
â”‚   â””â”€â”€ entities.json
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ crawler-contract.md
â”‚   â””â”€â”€ architecture.md
â”‚
â”œâ”€â”€ docker/                   # (optional) Docker setup
â”‚   â”œâ”€â”€ api.Dockerfile
â”‚   â”œâ”€â”€ ui.Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
````

---

## ğŸ§  How It Works

1. **Crawl** â†’ Save pages to `data/pages.jsonl` (one JSON per line).
2. **Extract** â†’ spaCy NER + title rules â†’ `data/entities.json`.
3. **Serve** â†’ FastAPI exposes endpoints.
4. **Visualize** â†’ Streamlit UI shows and exports results.

---

## ğŸ’» Run Locally

### 1) Clone & Setup

```bash
git clone https://github.com/PrakarshKaushik11/The-Coding-Penguins-Deviathon-2025.git
cd The-Coding-Penguins-Deviathon-2025
python -m venv .venv
# Windows:
.\.venv\Scripts\activate
# macOS/Linux:
# source .venv/bin/activate
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

### 2) Start the Backend API

```bash
uvicorn api.main:app --reload --port 8000
```

Open Swagger: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

### 3) Start the Frontend UI

```bash
streamlit run ui/app.py
```

Open: [http://localhost:8501](http://localhost:8501)

### 4) Try It

* Click **Run Extraction** (uses `data/pages.jsonl`).
* Click **Refresh Results** to view entities.
* **Download JSON** to save the output.

---

## ğŸ§° API Endpoints

| Method | Endpoint   | Description                       |
| -----: | ---------- | --------------------------------- |
|    GET | `/health`  | API health check                  |
|   POST | `/crawl`   | Crawl domain â†’ `data/pages.jsonl` |
|   POST | `/extract` | Run NLP â†’ `data/entities.json`    |
|    GET | `/results` | Return extracted entities JSON    |

---

## ğŸ Requirements

Install all dependencies:

```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

---

## ğŸ³ Docker (Optional)

```bash
docker-compose up --build
```

* Backend: [http://127.0.0.1:8000](http://127.0.0.1:8000)
* Frontend: [http://localhost:8501](http://localhost:8501)

---

## ğŸ Status

* âœ… Backend, NLP, and UI integrated
* âš™ï¸ Crawler module in progress (Om)
* ğŸš€ Ready for demo

---

## ğŸ§‘â€âš–ï¸ License

MIT License Â© 2025 â€” **Team The Coding Penguins**