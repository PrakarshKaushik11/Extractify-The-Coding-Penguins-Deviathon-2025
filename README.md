# ğŸ§  Extractify â€” The Coding Penguins Project (Deviathon 2025)

> âš¡ Crawl â†’ Extract â†’ Understand any domain using local AI  
> An **intelligent, offline information structuring system** that turns raw, unstructured website data into clean, organized knowledge.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-green.svg)](https://fastapi.tiangolo.com)
[![React](https://img.shields.io/badge/React-18+-blue.svg)](https://reactjs.org/)

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11 or higher
- Node.js 18+ (npm or bun)
- Git

### Installation & Running

```powershell
# 1. Clone the repository
git clone https://github.com/PrakarshKaushik11/Extractify-The-Coding-Penguins-Deviathon-2025.git
cd "Extractify - The Coding Penguins Project Deviathon 2025"

# 2. Backend Setup
# Create and activate virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1  # Windows
# source .venv/bin/activate    # Mac/Linux

# Install dependencies
pip install -r requirements.txt
python -m spacy download en_core_web_sm

# 3. Frontend Setup (in a new terminal)
cd ui
npm install  # or: bun install

# 4. Start Backend (terminal 1)
python -m uvicorn api.main:app --host 127.0.0.1 --port 8001 --reload

# 5. Start Frontend (terminal 2)
cd ui
npm run dev  # or: bun run dev
```

**Access the application:**
- ğŸŒ **Frontend UI:** http://localhost:8080
- ğŸ“š **Backend API Docs:** http://127.0.0.1:8001/docs
- â¤ï¸ **Health Check:** http://127.0.0.1:8001/api/health

---

## ğŸ§© Overview

**Extractify** is a full-stack AI system built for **Deviathon 2025** by *Team The Coding Penguins*.  
It automatically **crawls a domain**, **extracts key entities** (like Ministers, Judges, Officials, Professors), and **structures them** into a readable, exportable dataset â€” all **locally**, without needing any cloud services.

This project focuses on **domain-specific entity extraction** using a hybrid approach that combines:
- **spaCy NLP**
- **Regex pattern matching**
- **Zero-shot classification**

---

## âœ¨ Key Features

| Feature | Description |
|----------|-------------|
| ğŸ•·ï¸ **Automated Web Crawling** | Custom-built breadth-first crawler with link filtering and keyword-based targeting. |
| ğŸ§  **AI Entity Extraction** | Combines **spaCy**, regex, and zero-shot learning for high-accuracy entity recognition. |
| âš¡ **Offline Execution** | Works completely locally â€” no external API calls or internet AI dependencies. |
| ğŸ“Š **Structured Output** | Exports entities into **JSON format** for further use or integration. |
| ğŸ’» **Interactive UI** | Modern React + Tailwind dashboard to monitor progress and view results. |
| ğŸ”’ **Privacy-Centric** | All crawling and extraction happens locally on your machine. |

---

## ğŸ—ï¸ Architecture

```

Frontend (React + Tailwind)
â”‚
â–¼
FastAPI Backend  â†â†’  NLP Extractor (spaCy + Regex + Zero-shot)
â”‚
â–¼
Crawler (Requests + BeautifulSoup)
â”‚
â–¼
JSON Storage + Result Export

````

---

## âš™ï¸ Tech Stack

| Layer | Technology |
|-------|-------------|
| **Frontend** | React (Vite), Tailwind CSS, shadcn/ui, Framer Motion |
| **Backend** | FastAPI, Uvicorn |
| **NLP Engine** | spaCy 3.8, Regex, SentenceTransformer (Zero-shot) |
| **Crawler** | BeautifulSoup, Requests |
| **Storage** | Local JSON files (`data/pages.jsonl`, `data/entities.json`) |
| **Version Control** | Git + GitHub |
| **Execution** | Local environment (no cloud dependencies) |

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/PrakarshKaushik11/Extractify-The-Coding-Penguins-Deviathon-2025.git
cd "Extractify - The Coding Penguins Project Deviathon 2025"
````

---

## ğŸ“– How to Use

### Workflow

1. **Launch the application** (both backend and frontend)
2. **Open the UI** in your browser at http://localhost:8080
3. **Navigate to Crawl Settings** page
4. **Configure crawl parameters:**
   - Enter a **target domain** (e.g., `https://www.geeksforgeeks.org`)
   - Add **keywords** (comma-separated, e.g., `faculty, professor, teacher`)
   - Set **max pages** (10-500) and **crawl depth** (1-5)
5. **Click "Start Crawl"** â€” the system will:
   - Crawl the domain and collect pages
   - Extract entities using AI/NLP
   - Display real-time progress
6. **View Results** â€” see extracted entities in a dynamic table
7. **Export Data** â€” download results as CSV or JSON

### Tips for Best Results

- Use specific keywords related to your target entities
- Start with smaller page counts (50-100) for testing
- Increase depth for deeper site exploration
- Check the "AI Extraction" page for real-time progress

---

## ğŸ“‚ Project Structure

```
Extractify/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py              # FastAPI backend routes & logic
â”‚   â”œâ”€â”€ validators.py        # Input validation utilities
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ scraper.py           # Web crawler with BFS traversal
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ extractor/
â”‚   â”œâ”€â”€ nlp_pipeline.py      # AI/NLP entity extraction engine
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.tsx              # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ CrawlSettings.tsx    # Crawl configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ Extraction.tsx       # Real-time extraction view
â”‚   â”‚   â”‚   â”œâ”€â”€ Results.tsx          # Results table + export
â”‚   â”‚   â”‚   â””â”€â”€ SystemInfo.tsx       # System information
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Navigation.tsx       # Top navigation bar
â”‚   â”‚   â”‚   â””â”€â”€ StatCard.tsx         # Stats display component
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts               # Frontend API client
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â”œâ”€â”€ public/              # Static assets
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pages.jsonl          # Crawled pages (temporary)
â”‚   â””â”€â”€ entities.json        # Extracted entities (output)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ LICENSE                 # MIT License
â””â”€â”€ README.md               # This file
```

---

## ğŸ§  Example Output

```json
[
  {
    "name": "John Doe",
    "type": "Judge",
    "url": "https://www.justice.gov/news/john-doe-appointed",
    "snippet": "President announced John Doe as the new federal judge...",
    "score": 0.92
  },
  {
    "name": "Dr. Alice Smith",
    "type": "Professor",
    "url": "https://www.university.edu/faculty/alice-smith",
    "snippet": "Dr. Alice Smith specializes in AI and ethics...",
    "score": 0.89
  }
]
```

---

## ğŸ¯ Features in Detail

### ğŸ•·ï¸ Smart Web Crawler
- **BFS (Breadth-First Search)** traversal for systematic page discovery
- **Keyword-based prioritization** for relevant pages
- **Respects robots.txt** (can be disabled for testing)
- **Configurable depth and page limits**
- **Rate limiting** to avoid overwhelming servers

### ğŸ§  AI-Powered Entity Extraction
- **spaCy NLP** for named entity recognition
- **Semantic scoring** using SentenceTransformers
- **Context-aware extraction** with surrounding text analysis
- **Regex patterns** for phone numbers, addresses, years
- **Duplicate detection and merging**
- **Confidence scoring** for each entity

### ğŸ’» Modern Web Interface
- **Responsive design** with Tailwind CSS
- **Real-time progress tracking** during crawl/extraction
- **Dynamic table rendering** based on extracted fields
- **CSV/JSON export** capabilities
- **Stats dashboard** with entity counts and metrics
- **Dark theme** for comfortable viewing

---

## ï¿½ Team â€” *The Coding Penguins*

<table>
  <tr>
    <td align="center">
      <h3>ğŸ§  Prakarsh Kaushik</h3>
      <p><b>Team Lead | Backend & NLP</b></p>
      <p>FastAPI backend architecture<br>NLP pipeline integration<br>Project coordination</p>
    </td>
    <td align="center">
      <h3>ğŸ•·ï¸ Om Upadhyay</h3>
      <p><b>Crawler Developer</b></p>
      <p>Web crawler implementation<br>BFS algorithm & optimization<br>Link filtering logic</p>
    </td>
  </tr>
  <tr>
    <td align="center">
      <h3>ğŸ§© Pratiksha</h3>
      <p><b>NLP Engineer</b></p>
      <p>Entity extraction logic<br>Pattern matching rules<br>AI model integration</p>
    </td>
    <td align="center">
      <h3>ğŸ’» Priyanshu Gautam</h3>
      <p><b>Frontend Developer</b></p>
      <p>React UI/UX design<br>Component development<br>API integration</p>
    </td>
  </tr>
</table>

---

## ğŸ› Troubleshooting

### Backend won't start
- Ensure Python 3.11+ is installed: `python --version`
- Activate virtual environment: `.venv\Scripts\Activate.ps1`
- Install dependencies: `pip install -r requirements.txt`
- Download spaCy model: `python -m spacy download en_core_web_sm`

### Frontend won't start
- Ensure Node.js 18+ is installed: `node --version`
- Delete `node_modules` and reinstall: `rm -rf node_modules && npm install`
- Check if port 8080 is available

### Crawl timeout or no results
- Reduce `max_pages` and `max_depth` in Crawl Settings
- Try a simpler domain first (e.g., example.com)
- Check backend logs for errors

### No entities extracted
- Ensure keywords are relevant to the target domain
- Try broader keywords or remove keywords entirely
- Check if the crawled pages contain actual content (not just navigation)

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!  
Feel free to check the [issues page](https://github.com/PrakarshKaushik11/Extractify-The-Coding-Penguins-Deviathon-2025/issues).

---

## ğŸ“ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

You're free to use, modify, and distribute this project with proper attribution.

---

## ğŸ’™ Acknowledgements

- Built with â¤ï¸ by **The Coding Penguins** for **Deviathon 2025**
- Powered by **FastAPI**, **spaCy**, **React**, and **Tailwind CSS**
- Special thanks to:
  - Our mentors and organizers at Deviathon 2025
  - The open-source community for amazing tools
  - All judges and supporters of this project

---

## ğŸ“§ Contact

For questions, suggestions, or collaboration opportunities:

- **GitHub:** [PrakarshKaushik11](https://github.com/PrakarshKaushik11)
- **LinkedIn:** [Prakarsh Kaushik](https://www.linkedin.com/in/prakarsh-kaushik/)
- **Project Repository:** [Extractify-The-Coding-Penguins-Deviathon-2025](https://github.com/PrakarshKaushik11/Extractify-The-Coding-Penguins-Deviathon-2025)

---

<div align="center">
  <p><b>Made with ğŸ§ by The Coding Penguins</b></p>
  <p>â­ Star this repo if you find it helpful!</p>
</div>


