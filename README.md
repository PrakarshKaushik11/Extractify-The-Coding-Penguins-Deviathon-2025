# ğŸ§  Extractify â€” The Coding Penguins Project (Deviathon 2025)

> âš¡ Crawl â†’ Extract â†’ Understand any domain using local AI  
> An **intelligent, offline information structuring system** that turns raw, unstructured website data into clean, organized knowledge.

---

## ğŸ§© Overview

**Extractify** is a full-stack AI system built for **Deviathon 2025** by *Team The Coding Penguins*.  
It automatically **crawls a domain**, **extracts key entities** (like Ministers, Judges, Officials, Professors), and **structures them** into a readable, exportable dataset â€” all **locally**, without needing any cloud services.

This project focuses on **domain-specific entity extraction** using a hybrid approach that combines:
- **spaCy NLP**
- **Regex pattern matching**
- **Zero-shot classification**

---

## âœ¨ Key Features

| Feature | Description |
|----------|-------------|
| ğŸ•·ï¸ **Automated Web Crawling** | Custom-built breadth-first crawler with link filtering and keyword-based targeting. |
| ğŸ§  **AI Entity Extraction** | Combines **spaCy**, regex, and zero-shot learning for high-accuracy entity recognition. |
| âš¡ **Offline Execution** | Works completely locally â€” no external API calls or internet AI dependencies. |
| ğŸ“Š **Structured Output** | Exports entities into **JSON format** for further use or integration. |
| ğŸ’» **Interactive UI** | Modern React + Tailwind dashboard to monitor progress and view results. |
| ğŸ”’ **Privacy-Centric** | All crawling and extraction happens locally on your machine. |

---

## ğŸ—ï¸ Architecture

```

Frontend (React + Tailwind)
â”‚
â–¼
FastAPI Backend  â†â†’  NLP Extractor (spaCy + Regex + Zero-shot)
â”‚
â–¼
Crawler (Requests + BeautifulSoup)
â”‚
â–¼
JSON Storage + Result Export

````

---

## âš™ï¸ Tech Stack

| Layer | Technology |
|-------|-------------|
| **Frontend** | React (Vite), Tailwind CSS, shadcn/ui, Framer Motion |
| **Backend** | FastAPI, Uvicorn |
| **NLP Engine** | spaCy 3.8, Regex, SentenceTransformer (Zero-shot) |
| **Crawler** | BeautifulSoup, Requests |
| **Storage** | Local JSON files (`data/pages.jsonl`, `data/entities.json`) |
| **Version Control** | Git + GitHub |
| **Execution** | Local environment (no cloud dependencies) |

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/PrakarshKaushik11/Extractify-The-Coding-Penguins-Deviathon-2025.git
cd "Extractify - The Coding Penguins Project Deviathon 2025"
````

---

### 2ï¸âƒ£ Backend Setup (FastAPI)

```bash
cd api
python -m venv .venv
.venv\Scripts\activate   # On Windows
# or
source .venv/bin/activate   # On Mac/Linux

pip install -r requirements.txt
uvicorn main:app --reload --port 8000
```

Your backend will now run at:
â¡ï¸ **[http://127.0.0.1:8000](http://127.0.0.1:8000)**

---

### 3ï¸âƒ£ Frontend Setup (React + Vite)

```bash
cd ui
npm install
npm run dev
```

Your frontend runs at:
â¡ï¸ **[http://localhost:8080](http://localhost:8080)**

---

### 4ï¸âƒ£ Typical Workflow

1. Launch both backend and frontend
2. Open the UI in your browser
3. Enter a **target domain** (e.g. `https://www.codingblocks.com`)
4. Set **max pages** and **crawl depth**
5. Click **Start Crawl**
6. The system crawls â†’ extracts entities â†’ displays structured results
7. Export results as **JSON** from the Results page

---

## ğŸ“‚ Core Files

| Path                              | Description                                               |
| --------------------------------- | --------------------------------------------------------- |
| `/api/main.py`                    | FastAPI backend routes (`/crawl`, `/extract`, `/results`) |
| `/crawler/scraper.py`             | Domain crawler with BFS traversal & keyword filtering     |
| `/extractor/nlp_pipeline.py`      | NLP entity extraction pipeline                            |
| `/ui/src/pages/CrawlSettings.tsx` | Crawl configuration screen                                |
| `/ui/src/pages/Extraction.tsx`    | Real-time extraction view                                 |
| `/ui/src/pages/Results.tsx`       | Results dashboard + JSON export                           |
| `/ui/src/lib/api.ts`              | Frontend-backend connector                                |
| `/data/pages.jsonl`               | Stores crawled pages temporarily                          |
| `/data/entities.json`             | Stores extracted entities                                 |

---

## ğŸ§  Example Output

```json
[
  {
    "name": "John Doe",
    "type": "Judge",
    "url": "https://www.justice.gov/news/john-doe-appointed",
    "snippet": "President announced John Doe as the new federal judge...",
    "score": 0.92
  },
  {
    "name": "Dr. Alice Smith",
    "type": "Professor",
    "url": "https://www.university.edu/faculty/alice-smith",
    "snippet": "Dr. Alice Smith specializes in AI and ethics...",
    "score": 0.89
  }
]
```

---

## ğŸ’» UI Highlights

| Section               | Description                                        |
| --------------------- | -------------------------------------------------- |
| ğŸ  **Home**           | Start button to begin crawl & extraction           |
| âš™ï¸ **Crawl Settings** | Domain, keywords, page & depth configuration       |
| ğŸ¤– **AI Extraction**  | Live progress updates and analysis logs            |
| ğŸ“Š **Results**        | Table view of all extracted entities + JSON export |

---

## ğŸ‘©â€ğŸ’» Team â€” *The Coding Penguins*

| Member                  | Role                      | Contribution                                 |
| ----------------------- | ------------------------- | -------------------------------------------- |
| ğŸ§  **Prakarsh Kaushik** | Team Lead / Backend + NLP | Designed FastAPI backend and NLP integration |
| ğŸ•·ï¸ **Om Upadhyay**     | Web Crawler Developer     | Built the crawler (BFS + keyword filtering)  |
| ğŸ§© **Pratiksha**        | NLP Engineer              | Designed and refined entity extraction logic |
| ğŸ’» **Priyanshu Gautam** | Frontend Developer        | Built modern React + Tailwind UI             |

---

## ğŸ License

This project is licensed under the **MIT License** â€”
Youâ€™re free to use, modify, and enhance it with credit to the original authors.

---

## ğŸ’™ Acknowledgements

* Built with â¤ï¸ by **The Coding Penguins** for **Deviathon 2025**
* Powered by **FastAPI**, **spaCy**, and **React**
* Special thanks to our mentors, organizers, and judges for their guidance

---


